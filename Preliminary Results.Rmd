---
title: "DSE6211 Preliminary Results"
author: "Ryan Canfield"
date: "2024-06-11"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
```{r}
library(glmnet)         #For a Logistic Regression model.

# Addressed comment and removed extra models
library(MASS)
library(e1071)          # For a Support Vector Machine model.
library(neuralnet)      # For a basic Neural Network model.
library(keras)          # For a TensorFlow Neural Network model.
library(tensorflow)     # For a TensorFlow framework.
library(reticulate)     # For a python interface.
library(caret)          # For model training and evaluation.
library(ROCR)           # For ROC analysis.
library(tidyverse)      # For data manipulation.
library(ggplot2)        # For data visualizations. 
library(RColorBrewer)   # For coloring visuals.
library(forcats)        # For Manipulating and working with categorical variables. 

```

```{r}
# Reading the CSV file into a data frame
df <- read.csv("..\\Dataset\\project_data.csv")

# Display a preview of the data frame.
head(df)

```

```{r}
# For the proposed supervised classification, we can define the level "cancelled" as the positive class and "not cancelled" as the negative class. Then, once we build a classification model (for example, using a neural network) to predict booking_status, we can use the predicted probability of positive class (i.e., "cancelled") membership as the risk cancellation score. This predicted probability is between 0 and 1. Defining these classes as the positive and negative classes, respectively, also provides the appropriate context for evaluating the predicted probabilities using ROC curves and AUC (which we will cover during an upcoming week).

```

```{r}
### Preprocessing and addressing comments from Analytic Plan.

# Checking for missing values.
print(sum(is.na(df)))

# Addresses comment.
# Excluding Booking_ID since it is a unique identifier 
# Assuming 'df' is your dataframe
df <- df[, !(names(df) %in% "Booking_ID")]




# Addresses comment.
# Changes arrival date to season so when we use One Hot Encoding. 
# It doesn't create hundreds of extra columns, dimensionality, and space.
df$arrival_date <- as.Date(df[, "arrival_date"], format = "%m/%d/%Y")  
df$season <- ifelse(month(df$arrival_date) %in% c(12, 1, 2), "Winter",
                    ifelse(month(df$arrival_date) %in% c(3, 4, 5), "Spring",
                           ifelse(month(df$arrival_date) %in% c(6, 7, 8), "Summer",
                                  ifelse(month(df$arrival_date) %in% c(9, 10, 11), "Fall", NA))))
df$arrival_date <- df$season
df <- df[, -which(names(df) == "season")]

# This changes our target variable to numerical values without emposing heiracrhy or an extra column.
df$booking_status <- ifelse(df$booking_status == "not_canceled", 1, 0)

```

```{r}
# Changed from label encoding to One Hot encoding
for (col in names(df)) {  
  if (!is.numeric(df[[col]])) {
    # Perform one-hot encoding
    df <- cbind(df, model.matrix(~df[[col]] - 1))
    df <- df[, -which(names(df) == col)]
    cat("One-hot encoding applied to column:", col, "\n")
  }
}

```

```{r}
# Split the dataset into a training and testing set with an 80 - 20 split
set.seed(123)
ind <- createDataPartition(df$booking_status, p = 0.8, list = FALSE)
train <- df[ind, ] 
test <- df[-ind, ]

# Removing the target variable before scaling
train_booking_status <- train$booking_status
train <- subset(train, select = -booking_status)
test_booking_status <- test$booking_status
test <- subset(test, select = -booking_status)

# Scaling the data
train <- as.data.frame(scale(train))
test <-as.data.frame(scale(test))

#adding the variables back in
train$booking_status <- train_booking_status
test$booking_status <- test_booking_status

remove_prefix <- function(df) {
  colnames(df) <- gsub("df\\[\\[col\\]\\]", "", colnames(df))
  return(df)
}

train <- remove_prefix(train)
test <- remove_prefix(test)


```

```{r}
head(train)
head(test)
```

## First model: forward stepwise regression
```{r}
# Forward Stepwise Logestic Regression 

# Fit an intercept-only model
DF_Null_Model <- glm(booking_status ~ 1, data = train, family = binomial)

# fit a model with everything
DF_All_Model <- glm(booking_status ~ ., data = train, family = binomial)

# Forward stepwise selection using AIC with both null and full models
DF_Final_Model <- suppressWarnings(stepAIC(DF_Null_Model,
                          scope = list(lower = DF_Null_Model, upper = DF_All_Model),
                          direction = "forward",
                          trace = 0))


# Display the final model summary
summary(DF_Final_Model)

```

```{r}
# Obtain predicted probabilities on the testing set
predicted_probs <- predict(DF_Final_Model, newdata = test, type = "response")

# Assuming you have the true outcomes for the testing set (test_data$output)
observed_responses <- as.factor(test$booking_status)

# Convert predicted probabilities to binary predictions (e.g., using a threshold of 0.5)
predicted_classes <- as.factor(ifelse(predicted_probs >= 0.5, 1, 0))

# Create and displaying the confusion matrix
conf_matrix <- confusionMatrix(predicted_classes, observed_responses)
conf_matrix

```

```{r}
# Training the best SVM model 
best_svm_model <- svm(booking_status ~ ., 
                      data = train, 
                      kernel = "radial", 
                      cost = 5, 
                      gamma = 0.5)
```

```{r}
# Make predictions on the test data
predictions <- predict(best_svm_model, newdata = test)
predicted_classes2 <- as.factor(ifelse(predictions >= 0.5, 1, 0))
# Create and displaying the confusion matrix
conf_matrix2 <- confusionMatrix(predicted_classes2,  as.factor(test$booking_status))
conf_matrix2

```

```{r}
# Create the neural network model
#NNmodel <- neuralnet(formula = booking_status ~ no_of_adults + no_of_children + no_of_weekend_nights + no_of_week_nights +
#                       required_car_parking_space + lead_time + repeated_guest + no_of_previous_cancellations + 
#                       no_of_previous_bookings_not_canceled + avg_price_per_room + no_of_special_requests + meal_plan_1 +
#                       meal_plan_2 + meal_plan_3 + not_selected + room_type1 + room_type2 + room_type3 + room_type4 +
#                       room_type5 + room_type6 + room_type7 + Fall + Spring + Summer + Winter + aviation + complementary +
#                       corporate + offline + online,
#                     data = train,
#                     hidden = c(5,3,1),
#                     linear.output = TRUE)

# Plot the neural network
#plot(NNmodel)
```

```{r}
# Make predictions on the test data
#predictions3 <- predict(NNmodel, test)
#predicted_classes3 <- as.factor(ifelse(predictions3 >= 0.5, 1, 0))

# Create and displaying the confusion matrix
#conf_matrix3 <- confusionMatrix(predicted_classes3,  as.factor(test$booking_status))
#conf_matrix3
```















